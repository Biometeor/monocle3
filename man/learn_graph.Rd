% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learn_graph.R
\name{learn_graph}
\alias{learn_graph}
\title{Learn principal graph from the reduced space using reversed graph embedding}
\usage{
learn_graph(cds, use_partition = TRUE, close_loop = TRUE,
  learn_graph_control = NULL, verbose = FALSE)
}
\arguments{
\item{cds}{the cell_data_set upon which to perform this operation}

\item{close_loop}{Whether or not to perform an additional run of loop closing after running DDRTree or SimplePPT to identify potential loop structure in the data space}

\item{verbose}{Whether to emit verbose output during dimensionality reduction}

\item{rge_method}{Determines how to transform expression values prior to reducing dimensionality}

\item{scale}{When this argument is set to TRUE (default), it will scale each gene before running trajectory reconstruction.}

\item{euclidean_distance_ratio}{The maximal ratio between the euclidean distance of two tip nodes in the spanning tree inferred from SimplePPT algorithm and
that of the maximum distance between any connecting points on the spanning tree allowed to be connected during the loop closure procedure .}

\item{geodesic_distance_ratio}{The minimal ratio between the geodestic distance of two tip nodes in the spanning tree inferred from SimplePPT algorithm and
that of the length of the diameter path on the spanning tree allowed to be connected during the loop closure procedure. (Both euclidean_distance_ratio and geodesic_distance_ratio
need to be satisfied to introduce the edge for loop closure.)}

\item{prune_graph}{Whether or not to perform an additional run of graph pruning to remove small insignificant branches}

\item{minimal_branch_len}{The minimal length of the diameter path for a branch to be preserved during graph pruning procedure}

\item{orthogonal_proj_tip}{Whether to perform orthogonal projection for cells corresponding to the tip principal points. Default to be FALSE}

\item{...}{additional arguments to pass to the dimensionality reduction function}
}
\value{
an updated cell_data_set object
}
\description{
Monocle3 aims to learn how cells transition through a
biological program of gene expression changes in an experiment. Each cell
can be viewed as a point in a high-dimensional space, where each dimension
describes the expression of a different gene. Identifying the program of
gene expression changes is equivalent to learning a \emph{trajectory} that
the cells follow through this space. However, the more dimensions there are
in the analysis, the harder the trajectory is to learn. Fortunately, many
genes typically co-vary with one another, and so the dimensionality of the
data can be reduced with a wide variety of different algorithms. Monocle3
provides two different algorithms for dimensionality reduction via
\code{reduce_dimension}.
Both take a cell_data_set object and a number of dimensions allowed for the
reduced space. You can also provide a model formula indicating some variables
(e.g. batch ID or other technical factors) to "subtract" from the data so it
doesn't contribute to the trajectory.
}
\details{
You can choose two different reduction algorithms: Independent Component
Analysis (ICA) and Discriminative Dimensionality Reduction with Trees (DDRTree).
The choice impacts numerous downstream analysis steps, including \code{\link{order_cells}}.
Choosing ICA will execute the ordering procedure described in Trapnell and Cacchiarelli et al.,
which was implemented in Monocle version 1. \code{\link[DDRTree]{DDRTree}} is a more recent manifold
learning algorithm developed by Qi Mao and colleages. It is substantially more
powerful, accurate, and robust for single-cell trajectory analysis than ICA,
and is now the default method.

Often, experiments include cells from different batches or treatments. You can
reduce the effects of these treatments by transforming the data with a linear
model prior to dimensionality reduction. To do so, provide a model formula
through \code{residual_model_formula_str}.
}
\references{
DDRTree: Qi Mao, Li Wang, Steve Goodison, and Yijun Sun. Dimensionality reduction via graph structure learning. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 765â€“774. ACM, 2015.

L1graph (generalized SimplePPT): Qi Mao, Li Wang, Ivor Tsang, and Yijun Sun. Principal graph and structure learning based on reversed graph embedding . IEEE Trans. Pattern Anal. Mach. Intell., 5 December 2016.

Original SimplePPT: Qi Mao, Le Yang, Li Wang, Steve Goodison, Yijun Sun. SimplePPT: A Simple Principal Tree Algorithm https://epubs.siam.org/doi/10.1137/1.9781611974010.89
}
